---
layout: post
title: go-bt-1
excerpt: "Write a BitTorrent client from scratch in Go: part 1"
categories: [coding]
tags: [howto,golang]
---

First post in what will (hopefully?) be building an *extremely* simple BitTorrent client in Go. At the very least we'll aimto parse `.torrent` files, connect to peers and download files. Just to managing expectations, incoming requests (uploads), DHT and the like will likely be left as an exercise to the reader.

_Note_: most (if not all) of the snippets should be using `any` instead of `any` - the 2 are now interchangeable

# `bencode`

If you have ever downloaded a `.torrent` file from say, [Ubuntu](https://ubuntu.com/download/alternative-downloads#bit-torrent) and tried to open it in a file editor, you'll be hard pressed to call this readable. The file is encoded in a format called `bencode`, the specification of which is available [here](https://wiki.theory.org/BitTorrentSpecification#Bencoding).

The TL;DR is that we can use it to represent basic types - e.g. a positive integer is represented as a stream starting with `i` and ending with `e`. So 123 would be encoded as `i123e`. Lists have a similar setup - with `l` being the start delimiter. So the list `[123,456]` would be represented as `li123ei456ee`. Lists can contain other lists too!

Byte strings (I guess that'd be `char` in C?) are a little different in that they start with a number representing the length, delimited by `:` - so "foo" would be encoded as `3:foo`.

Dictionaries are similar to lists, starting with a `d` (easy heh?). Keys must be sorted in byte order and must be byte strings - so the Python dict `{'foo': 123}` would be encoded as `d3:fooi123ee`.

# Approach

If you have ever used a stream-based parser like `StAX` for XML, or `PyYAML`, we'll be doing something somewhat similar. Take this list with a nested element for example:

```
[1, [2], 3] = li1eli2eei3ee
```

As we process the stream, the structure looks a little bit like a tree:

```
[
    1,
    [
        2
    ],
    3
]
```

When we encounter the first `[` we set the "node type" to a list, and recursively call our parser with the remaining of the stream. After reading `1` we look to see if we had a root note - we had and it's a list, so we append the value to it. We keep recursively call ourselves with the remaining bytes of the stream. In pseudo code, this looks a bit like:

```
parse(<holder>, 'li1eli2eei3ee')
    parse([, 'i1eli2eei3ee')
    parse([1, 'li2eei3ee')
        parse([1,[,'i2eei3ee')
        parse([1,[2,'ei3ee')
            return [2]
        parse([1,[2],'i3ee')
        parse([1,[2],3, 'e')
        parse([1,[2],3], '')
return [1,[2],3]
```

# Interface, "data" holders

Here's the general interface - we only need 2 methods. One to add value as we see them, and one to return the contents.

{% highlight golang %}
type Holder interface {
	Add(value any)
	Obj() any
}
{% endhighlight %}

Here are the basic type (`List`, `Dict` and `Value` - the latter is for scalars of all kinds):

{% highlight golang %}
type ListHolder struct {
	List []any
}

type DictHolder struct {
	Dict map[string]any
	// tracks the current key
	Key string
}

type ValueHolder struct {
	Val any
}
{% endhighlight %}

Their implementation of the `Holder` interface is as follows:

{% highlight golang %}
// Add methods

func (c *ListHolder) Add(value any) {
	c.List = append(c.List, value)
}

func (c *DictHolder) Add(value any) {
	if c.Key == "" {
		c.Key = value.(string)
	} else {
		c.Dict[c.Key] = value
		// reset
		c.Key = ""
	}
}

func (c *ValueHolder) Add(value any) {
	c.Val = value
}

// Obj methods

func (c *ListHolder) Obj() any {
	return c.List
}

func (c *DictHolder) Obj() any {
	return c.Dict
}

func (c *ValueHolder) Obj() any {
	return c.Val
}
{% endhighlight %}

The only one worth a mention is the `DictHolder`. When we finish processing an element inside the `dict`, we need to know hwhether it was a key or a value - so we use `c.Key` internally as a toggle. If it's set, the next call to `Add` is for a value - and if not, it's the start of a key.

# Parsing

Now we almost ready to start parsing the stream! Let's start with some basic tests (TDD FTW!) to ensure we're doing the right thing. It's not full coverage but should be enough to help us flush out silly mistakes.

{% highlight golang %}
func TestBencodeRecursiveParser(t *testing.T) {
        // negative int!
		r := bytes.NewReader([]byte("i-42e"))
		ret := data.ParseBencoded2(r)
		if ret != -42 {
			t.Errorf("expected -42, got %v", ret)
		}

		// string, below 10 chars
		r = bytes.NewReader([]byte("3:foo"))
		ret = data.ParseBencoded2(r).(string)
		if ret != "foo" {
			t.Errorf("expected 'foo', got %v", ret)
		}

		// string, above 10 chars
		r = bytes.NewReader([]byte("12:foobarraboof"))
		ret = data.ParseBencoded2(r).(string)
		if ret != "foobarraboof" {
			t.Errorf("expected 'foo', got %v", ret)
		}

		// list with one int
		r = bytes.NewReader([]byte("li42ee"))
		retSlice, _ := data.ParseBencoded2(r).([]interface{})
		if len(retSlice) != 1 && retSlice[0] != 42 {
			t.Errorf("expected [42], got %v", ret)
		}

		// list with two items
		r = bytes.NewReader([]byte("li42ei43ee"))
		retSlice, _ = data.ParseBencoded2(r).([]interface{})
		if len(retSlice) != 2 && retSlice[0] != 42 && retSlice[1] != 43 {
			t.Errorf("expected [42, 43], got %v", ret)
		}

		// a simple map
		r = bytes.NewReader([]byte("d3:fooi42ee"))
		retMap, _ := data.ParseBencoded2(r).(map[string]interface{})
		if retMap["foo"] != 42 {
			t.Errorf("expected [42], got %v", retMap)
		}

		// a map with a list
		r = bytes.NewReader([]byte("d3:fooli42eee"))
		retMap, _ = data.ParseBencoded2(r).(map[string]interface{})
		retSlice = retMap["foo"].([]interface{})
		if len(retSlice) != 1 && retSlice[0] != 42 {
			t.Errorf("expected {'foo': [42]}, got %v", ret)
		}
}
{% endhighlight %}

The parsing is split into 2 - we have the public interface `ParseBencoded2` (2 because my first impl wasn't something to be proud of), and the internal *recursive* parsing function called `parseBencodeStream`. The `check` function is a little helper to help catch issues early. I like a good debugging session as much as the next person but that's simpler than letting errors propagate.

{% highlight golang %}
func check(err error) {
	if err != nil {
		if err != io.EOF {
			panic(err)
		}
	}
}

func parseBencodeStream(container Holder, reader *bufio.Reader) Holder {
	b, err := reader.ReadByte()
	if err != nil {
		return container
	}
	switch b {
	case 'e':
		return container
	case 'i':
		buff, err := reader.ReadBytes('e')
		check(err)
		val, err := strconv.Atoi(string(buff[:len(buff)-1]))
		check(err)
		container.Add(val)
		return parseBencodeStream(container, reader)
	case 'l':
		c := parseBencodeStream(&ListHolder{List: make([]any, 0)}, reader)
		container.Add(c.(*ListHolder).List)
		return parseBencodeStream(container, reader)
	case 'd':
		c := parseBencodeStream(&DictHolder{Dict: make(map[string]any)}, reader)
		container.Add(c.(*DictHolder).Dict)
		return parseBencodeStream(container, reader)
	case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		buff, err := reader.ReadBytes(':')
		check(err)
		strLen := string(b)
		if len(buff) > 1 {
			strLen += string(buff[:len(buff)-1])
		}
		strLenInt, err := strconv.Atoi(strLen)
		check(err)
		val := make([]byte, strLenInt)
		for i := 0; i < strLenInt; i++ {
			b, err = reader.ReadByte()
			check(err)
            val[i] = b
		}
		container.Add(string(val[:])
		return parseBencodeStream(container, reader)
	}
	return container
}

func ParseBencoded2(r io.Reader) any {
	reader := bufio.NewReader(r)

	// kick this off by passing an empty holder
	container := parseBencodeStream(&ValueHolder{}, reader)
	return container.Obj()
}
{% endhighlight %}

We kick things off with a `ValueHolder` (because we expect to return a single value - `i1ei2e` wouldn't be "valid" per se, it'd need to be in a container) and a pointer to `bufio.Reader`, which allows us to continuously read form the same stream. We read a byte at a time in some cases, and in others until we hit a specific delimiter (e.g. `e` for integers, `:` for strings etc...). If we find a new container delimiter we create the appropriate holder (for a list or a map) and recurse accordingly.

Running our tests shows we're home free:
```
/V/r/c/g/src ❯❯❯ go test ./data
ok      go-bt/data      0.351s
```

# Encoding

We're half-way there. We can parse data, let's make sure we can serialise it back. The beauty of this is that from a test perspective, `encode(parse(data))` is equivalent to the identity function! That is, this is just equal to `data`. A bit like decompressing a compressed file.

_Caveat emptor_: the encoding code will be sufficient for BitTorrent but isn't comprehensive enough to support all kinds of types!

If you've ever used reflection in say, Java, you'll appreciate how terse it is in golang! As with the parser, we'll need to recurse on each value in a container. For maps that means we'll need to first encode the key, then the value. For lists, we'll need to encode each elemenet.

As done previously, let's start with some tests:
{% highlight golang %}

{% endhighlight %}

{% highlight golang %}
func Encode(buffer *bytes.Buffer, o any) {
	value := reflect.ValueOf(o)
	switch value.Kind() {
	case reflect.Int, reflect.Int16, reflect.Int32, reflect.Int64:
		buffer.WriteByte('i')
		buffer.WriteString(strconv.Itoa(int(value.Int())))
		buffer.WriteByte('e')
	case reflect.Uint, reflect.Uint16, reflect.Uint32, reflect.Uint64:
		buffer.WriteByte('i')
		buffer.WriteString(strconv.Itoa(int(value.Uint())))
		buffer.WriteByte('e')
	case reflect.String:
		buffer.WriteString(strconv.Itoa(len(value.Interface().(string))))
		buffer.WriteString(":")
		buffer.WriteString(value.Interface().(string))
	case reflect.Slice:
		buffer.WriteByte('l')
		// so this is a bit funky - we can't convert e.g. []int to []any directly
		temp := make([]any, value.Len())

		for i := 0; i < value.Len(); i++ {
			temp[i] = value.Index(i).Interface()
		}
		for _, val := range temp {
			Encode(buffer, val)
		}
		buffer.WriteByte('e')
	case reflect.Map:
		buffer.WriteByte('d')
		temp := make(map[string]any, value.Len())

		// we need a map[string]any
		iter := value.MapRange()
		for iter.Next() {
			k := iter.Key()
			v := iter.Value()
			temp[k.Interface().(string)] = v.Interface()
		}

		// keys need to be sorted alphabetically
		keys := make([]string, 0, len(temp))
		for k := range temp {
			keys = append(keys, k)
		}
		slices.Sort(keys)

		for _, key := range keys {
			// first we write the key
			Encode(buffer, key)
			// then the value
			Encode(buffer, temp[key])
		}
		buffer.WriteByte('e')
	default:
		panic(fmt.Sprintf("can't handle type %s", value.Kind()))
	}
}
{% endhighlight %}


# Struct tags

I'm saddened to say the above was the fun part. 

{% highlight golang %}
{% endhighlight %}

# Finally - parsing a `.torrent` file!

# Taking it further
